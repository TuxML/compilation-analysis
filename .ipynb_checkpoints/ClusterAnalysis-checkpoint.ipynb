{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "errorlogs = pd.read_pickle('errlogs.pkl')\n",
    "# found thanks to clustering! \n",
    "suspicious_cids = [70715, 70716, 74459, 74460, 74461, 74463, 74464]\n",
    "for cid in suspicious_cids:\n",
    "    errorlogs = errorlogs[errorlogs.cid != cid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errorlogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorlogs.loc[3]['error_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "class ErrorLog(Enum):\n",
    "    BLACKLIGHT = auto(),\n",
    "    BLACKLIGHT2 = auto(),\n",
    "    CONFIG_NLS_DEFAULT = auto(),\n",
    "    CRC32 = auto(),\n",
    "    V4L2 = auto(), \n",
    "    OVERFLOW2 = auto(), \n",
    "    ULPI = auto(), \n",
    "    PCM = auto(),\n",
    "    TTM = auto(), \n",
    "    AS68K = auto(), \n",
    "    GEN = auto(), \n",
    "    AICDB = auto(), \n",
    "    AIC7XXX = auto(),\n",
    "    DRM_BRIDGE = auto(),\n",
    "    PINCTRL = auto(), \n",
    "    BTBCM = auto(),\n",
    "    BPFFANCY = auto(), \n",
    "    DEVM = auto(), \n",
    "    DEVM2 = auto(), \n",
    "    I2C = auto() \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "patterns = { ErrorLog.BLACKLIGHT : \"undefined reference to `backlight_device\",\n",
    "            ErrorLog.BLACKLIGHT2: 'error: ‘intel_backlight_device_register’', # 'intel_backlight_device_register', # cid 87044 does not match BACKLIGHT \n",
    "            ErrorLog.CONFIG_NLS_DEFAULT : \"CONFIG_NLS_DEFAULT\",\n",
    "            ErrorLog.CRC32 : 'undefined reference to `crc32', \n",
    "            ErrorLog.V4L2 : 'undefined reference to `v4l2',\n",
    "            ErrorLog.OVERFLOW2 : '__read_overflow2',\n",
    "            ErrorLog.ULPI : 'undefined reference to `ulpi', # 100-126K dataset\n",
    "            ErrorLog.PCM : 'undefined reference to `atmel_pcm_dma_platform', # 100-126K dataset\n",
    "            ErrorLog.TTM : 'undefined reference to `ttm', \n",
    "            ErrorLog.AS68K: 'as68k: not found',\n",
    "            ErrorLog.GEN : 'undefined reference to `gen_pool', \n",
    "            ErrorLog.AIC7XXX: '[drivers/scsi/aic7xxx/aicasm/aicasm] Error 2', #'drivers/scsi/aic7xxx',\n",
    "            ErrorLog.AICDB : 'aicdb.h: No such file or directory', \n",
    "            ErrorLog.DRM_BRIDGE : 'undefined reference to `drm_panel_bridge_add', \n",
    "            ErrorLog.PINCTRL : '[drivers/pinctrl/pinctrl-mcp23s08.o] Error', #'pinctrl-mcp23s08', # loosely pattern (too general?)\n",
    "            ErrorLog.BTBCM : 'undefined reference to `btbcm_set_bdaddr', \n",
    "            ErrorLog.BPFFANCY : 'bpf-fancy', # loosely pattern (too general?)\n",
    "            ErrorLog.DEVM : 'undefined reference to `__devm_regmap',\n",
    "            ErrorLog.I2C: 'error: implicit declaration of function ‘i2c_get_adapter’', #'i2c_get_adapter',\n",
    "            ErrorLog.DEVM2 : 'undefined reference to `devm_of_led'\n",
    "           }\n",
    "\n",
    "pattern_name = [name for name, member in ErrorLog.__members__.items()]\n",
    "error_pattern = pd.DataFrame(columns=pattern_name, index=errorlogs['cid'])\n",
    "error_pattern.fillna(False, inplace=True)\n",
    "\n",
    "for i, errorlog in errorlogs.iterrows():\n",
    "    error = errorlog['error_message']\n",
    "    cid = errorlog['cid']\n",
    "    for k, p in patterns.items():\n",
    "        if (p in error):\n",
    "            error_pattern.loc[cid][k.name] = True\n",
    "            #print (k.name, \"found in configuration\", cid)\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same, except we use the first error message (and only it)\n",
    "# it mimics basic Linux build process\n",
    "# see discussion here: https://github.com/TuxML/compilation-analysis/issues/1#issuecomment-488711237\n",
    "\n",
    "pattern_name = [name for name, member in ErrorLog.__members__.items()]\n",
    "error_patternfirst = pd.DataFrame(columns=pattern_name, index=errorlogs['cid'])\n",
    "error_patternfirst.fillna(False, inplace=True)\n",
    "\n",
    "for i, errorlog in errorlogs.iterrows():\n",
    "    error = errorlog['error_message']\n",
    "    cid = errorlog['cid']\n",
    "    #print(cid)\n",
    "    for err in error.splitlines():\n",
    "        found = False\n",
    "        for k, p in patterns.items():\n",
    "            if found:\n",
    "                break\n",
    "            if (p in err):\n",
    "                error_patternfirst.loc[cid][k.name] = True\n",
    "                found = True\n",
    "                #print (k, \"found\")\n",
    "        if found:\n",
    "            break\n",
    "    #for k, p in patterns.items():\n",
    "    #    if (p in error):\n",
    "    #        error_patternfirst.loc[cid][k.name] = True\n",
    "            #print (k.name, \"found in configuration\", cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_patternfirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_pattern.loc[99949]['BLACKLIGHT'] = True\n",
    "error_pattern['CONFIG_NLS_DEFAULT'].value_counts()\n",
    "#error_pattern.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "def nb_patterns(row):\n",
    "    return sum(row == True)                    \n",
    "error_pattern['nb_patterns'] = error_pattern.apply(nb_patterns, axis=1)\n",
    "pattern_frequencies = error_pattern[pattern_name].apply(nb_patterns, axis=0)\n",
    "pattern_frequencies.plot(kind='bar')\n",
    "pattern_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "error_patternfirst['nb_patterns'] = error_patternfirst.apply(nb_patterns, axis=1)\n",
    "patternfirst_frequencies = error_patternfirst[pattern_name].apply(nb_patterns, axis=0)\n",
    "patternfirst_frequencies.plot(kind='bar')\n",
    "patternfirst_frequencies\n",
    "# np.unique(error_patternfirst['nb_patterns'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern['nb_patterns'].hist()\n",
    "error_pattern.query(\"AIC7XXX == False\")['nb_patterns'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.sort_values(by='nb_patterns', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_pattern['CONFIG_NLS_DEFAULT'].value_counts().plot(kind='bar')\n",
    "error_pattern.query('nb_patterns == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.query('nb_patterns == 0').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cid in error_pattern.query('nb_patterns == 0').index:\n",
    "    print (\"configuration cid\", cid)\n",
    "    #if cid in suspicious_cids:\n",
    "    #    print(\"false positive failure\")\n",
    "    #    continue\n",
    "    \n",
    "    error_message = errorlogs.query(\"cid == \" + str(cid))['error_message'].values\n",
    "    for err in error_message[0].splitlines():\n",
    "        if \"Cyclomatic\" not in err:\n",
    "            print (err)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "# 74459, 74460, 74461, 74463, 74464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.query('nb_patterns >= 2 & (AS68K == True & AIC7XXX == False)').sort_values(by='nb_patterns', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.query('nb_patterns >= 2 & (AS68K == False & AIC7XXX == False & AICDB == True)').sort_values(by='nb_patterns', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_pattern.query('nb_patterns == 2 & (as68k == False & AIC7XXX == True)').sort_values(by='nb_patterns', ascending=False)\n",
    "error_pattern.query('nb_patterns >= 2 & (AS68K == False & AICDB == False & AIC7XXX == True)').sort_values(by='nb_patterns', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.query('nb_patterns >= 2 & (AS68K == False & AIC7XXX == False)').sort_values(by='nb_patterns', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking effect\n",
    "error_pattern.query('nb_patterns >= 2 & CONFIG_NLS_DEFAULT == True').sort_values(by='nb_patterns', ascending=False)\n",
    "error_pattern.query('CONFIG_NLS_DEFAULT == True').sort_values(by='nb_patterns', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking effect\n",
    "error_pattern.query('GEN == True').sort_values(by='nb_patterns', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.query('BLACKLIGHT == True').sort_values(by='nb_patterns', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice masking effect!\n",
    "error_pattern.query('PINCTRL == True & (AS68K == False & AIC7XXX == False)').sort_values(by='nb_patterns', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice masking effect!\n",
    "error_pattern.query('I2C == True & (PINCTRL == False & AS68K == False & AIC7XXX == False)').sort_values(by='nb_patterns', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# see Hugo notebook here!\n",
    "with open(\"option_columns.json\",\"r\") as f:\n",
    "    option_columns = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata = pd.read_csv(\"dataset_after_encoding.csv\", dtype={k:\"int8\" for k in option_columns})\n",
    "rawtuxdata.info(memory_usage='deep')\n",
    "rawtuxdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_head = [\"cid\", \"time\", \"date\"] # \"compile\"\n",
    "compilation_status_column_name = 'compile_success'\n",
    "size_methods = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \n",
    "              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "TESTING_SIZE= 0.001 #0.99 # 0.001 # 0.9\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    rawtuxdata\n",
    "    .drop(columns=[\"cid\"])\n",
    "    .drop(columns=size_methods)\n",
    "    .drop(columns=compilation_status_column_name), \n",
    "    rawtuxdata[compilation_status_column_name], test_size=TESTING_SIZE, random_state=0)  \n",
    "clf = tree.DecisionTreeClassifier() #GradientBoostingClassifier(n_estimators=100) #RandomForestRegressor(n_estimators=100) #   #GradientBoostingRegressor(n_estimators=100)  \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score (y_test, y_pred)\n",
    "prec = precision_score (y_test, y_pred)\n",
    "reca = recall_score (y_test, y_pred)\n",
    "f1 = f1_score (y_test, y_pred)\n",
    "balance_acc = balanced_accuracy_score (y_test, y_pred)\n",
    "print(\"Accuracy score:\", acc)\n",
    "print(\"Precision score:\", prec)\n",
    "print(\"Recall score:\", reca)\n",
    "print(\"F1 score:\", f1)\n",
    "print(\"Balance accuracy score:\", balance_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "\n",
    "def printTree(clf, feature_names):\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=feature_names,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(\"TUXML_compilation_failures\")\n",
    "    \n",
    "printTree(clf, rawtuxdata.drop(columns=[\"cid\"]).drop(columns=size_methods).drop(columns=compilation_status_column_name).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_rules(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    #print (\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, previous_rules):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #print (\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], previous_rules+[name + \" <= \" + str(threshold)])\n",
    "            #print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], previous_rules+[name + \" > \" + str(threshold)])\n",
    "        else:\n",
    "            print(\" & \".join(previous_rules) + \" ---> \" + str(tree_.value[node]))\n",
    "\n",
    "    recurse(0, [])\n",
    "    \n",
    "tree_to_rules(clf, rawtuxdata.drop(columns=[\"cid\"]).drop(columns=size_methods).drop(columns=compilation_status_column_name).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_failure_rules(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    #print (\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, previous_rules, acc):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #print (\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], previous_rules+[name + \" <= \" + str(threshold)], acc)\n",
    "            #print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], previous_rules+[name + \" > \" + str(threshold)], acc)\n",
    "        else:\n",
    "            if tree_.value[node][0][0] > tree_.value[node][0][1]:\n",
    "                #print(\" & \".join(previous_rules) + \" ---> \" + str(tree_.value[node]))\n",
    "                acc.append(\" & \".join(previous_rules))\n",
    "\n",
    "    acc = []\n",
    "    recurse(0, [], acc)\n",
    "    return acc\n",
    "    \n",
    "all_paths = tree_to_failure_rules(clf, rawtuxdata.drop(columns=[\"cid\"]).drop(columns=size_methods).drop(columns=compilation_status_column_name).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def find_rule_for_configuration(tree, feature_names, configuration):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, previous_rules, configuration):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #print (\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            if configuration[name] <= threshold:\n",
    "                recurse(tree_.children_left[node], previous_rules+[name + \" <= \" + str(threshold)], configuration)\n",
    "            #print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            else:\n",
    "                recurse(tree_.children_right[node], previous_rules+[name + \" > \" + str(threshold)], configuration)\n",
    "        else:\n",
    "            #if tree_.value[node][0][0] > tree_.value[node][0][1]:\n",
    "            print(\" & \".join(previous_rules))\n",
    "    \n",
    "    recurse(0, [], configuration)\n",
    "    \n",
    "def find_rule_for_configuration_id(cid):\n",
    "    return find_rule_for_configuration(clf, rawtuxdata.drop(columns=[\"cid\"]).drop(columns=size_methods).drop(columns=compilation_status_column_name).columns, rawtuxdata.query(\"cid == \" + str(cid)).iloc[0]) \n",
    "\n",
    "find_rule_for_configuration_id(92072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.query(\"AIC7XXX_BUILD_FIRMWARE == 1 | AIC79XX_BUILD_FIRMWARE == 1 | WANXL_BUILD_FIRMWARE == 1\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.query(\"(AIC7XXX_BUILD_FIRMWARE == 0 & AIC79XX_BUILD_FIRMWARE == 0) & WANXL_BUILD_FIRMWARE == 1\")['compile_success'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.query(\"AIC7XXX_BUILD_FIRMWARE == 0 & AIC79XX_BUILD_FIRMWARE == 0 & WANXL_BUILD_FIRMWARE == 0 & compile_success == False\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "basic conclusion: bug GENERIC_ALLOCATOR + DRM_VBOXVIDEO is always masked by firmwares-like failures\n",
    "'''\n",
    "generic_allocator_mask_firmwares = rawtuxdata.query(\"GENERIC_ALLOCATOR == 0 & DRM_VBOXVIDEO == 2 & (AIC7XXX_BUILD_FIRMWARE == 1 | AIC79XX_BUILD_FIRMWARE == 1 | WANXL_BUILD_FIRMWARE == 1)  & compile_success == False\")\n",
    "print(\"generic allocator bug with firmwares' failures\", generic_allocator_mask_firmwares.shape)\n",
    "print()\n",
    "print()\n",
    "for cid in generic_allocator_mask_firmwares['cid']:\n",
    "    print (\"###### configuration id\", cid)\n",
    "    err_pattern = error_pattern.query(\"cid == \" + str(cid)).iloc[0]\n",
    "    for err in ErrorLog:\n",
    "        if (err_pattern[err.name]):\n",
    "            print(err)\n",
    "    error_messages = errorlogs.query(\"cid == \" + str(cid)).iloc[0]['error_message'].splitlines()\n",
    "    for error in error_messages:\n",
    "        if \"Cyclomatic \" not in error:\n",
    "            print(error)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "basic conclusion: bug GENERIC_ALLOCATOR + DRM_VBOXVIDEO is not masked by other failures\n",
    "but may mask other failures \n",
    "'''\n",
    "\n",
    "generic_allocator_mask_notfirmware = rawtuxdata.query(\"GENERIC_ALLOCATOR == 0 & DRM_VBOXVIDEO == 2 & ~(AIC7XXX_BUILD_FIRMWARE == 1 | AIC79XX_BUILD_FIRMWARE == 1 | WANXL_BUILD_FIRMWARE == 1)  & compile_success == False\")\n",
    "\n",
    "\n",
    "print(\"generic allocator bug *without* firmwares' failures\", generic_allocator_mask_notfirmware.shape)\n",
    "print()\n",
    "print()\n",
    "for cid in generic_allocator_mask_notfirmware['cid']:\n",
    "    err_pattern = error_pattern.query(\"cid == \" + str(cid)).iloc[0]\n",
    "    if not (err_pattern[ErrorLog.GEN.name]):\n",
    "        print (\"###### configuration id\", cid)\n",
    "        print(\"GENERIC allocator NOT found\")\n",
    "    #else:\n",
    "    #    for err in ErrorLog:\n",
    "    #        if (err_pattern[err.name]):\n",
    "    #            print(err)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~(AIC7XXX_BUILD_FIRMWARE == 1 | AIC79XX_BUILD_FIRMWARE == 1 | WANXL_BUILD_FIRMWARE == 1)  &\n",
    "# Mathieu: I'm deactivating it, it's time-consuming and error-prone \n",
    "if False:\n",
    "    for path1 in all_paths[::-1]:\n",
    "        # collect all cids related to a path\n",
    "        path_cids = rawtuxdata.query(path1 + \" & compile_success == False\")['cid'].values\n",
    "        spath_cids = set(path_cids)\n",
    "        print (path1)\n",
    "        for path2 in all_paths[::-1]:\n",
    "            if (path1 != path2):                \n",
    "                for cid in path_cids:\n",
    "                    # report whether an alternate path/rule can match the cid \n",
    "                    #print (cid)\n",
    "                    overlap = rawtuxdata.query(path2 + \" & compile_success == False & cid == \" + str(cid)) #['cid'].values\n",
    "                    #overlap = list(spath_cids & set(path_cids2)) \n",
    "                    if len(overlap) > 0:\n",
    "                        print(path1, \"also hold with\\n\", path2, \"=> #\", overlap)\n",
    "                        print()\n",
    "    \n",
    "       \n",
    "#    for path2 in all_paths:\n",
    "#        if (path1 != path2):\n",
    "#            overlap = len(rawtuxdata.query(path1 + \" | ~(\" + path2 + \") & compile_success == False\").index)\n",
    "#            if  overlap > 0:\n",
    "#                print(path1, \"also hold with\\n\", path2, \"=> #\", overlap)\n",
    "#                print()\n",
    "        \n",
    "        \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: classification on clusters!\n",
    "rawtuxdata = pd.merge(rawtuxdata, error_patternfirst, on='cid', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.shape, error_patternfirst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.query(ErrorLog.AICDB.name + \" == True\").shape\n",
    "# rawtuxdata['cid']\n",
    "# configwithclusters['cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING_SIZE= 0.9 #0.99 # 0.001 # 0.9\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    rawtuxdata\n",
    "#    .drop(columns=[\"cid\"])\n",
    "    #.drop(columns=pattern_name)\n",
    "#    .drop(columns=size_methods)\n",
    "#    .drop(columns=compilation_status_column_name), \n",
    "#    rawtuxdata[ErrorLog.AICDB.name], test_size=TESTING_SIZE, random_state=0)  \n",
    "\n",
    "#clf = tree.DecisionTreeClassifier() #GradientBoostingClassifier(n_estimators=100) #RandomForestRegressor(n_estimators=100) #   #GradientBoostingRegressor(n_estimators=100)  \n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "#                         feature_names=feature_names,  \n",
    "#                         filled=True, rounded=True,\n",
    "#                         special_characters=True)  \n",
    "#graph = graphviz.Source(dot_data)  \n",
    "#graph.render(\"TUXML_compilation_failures_clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
