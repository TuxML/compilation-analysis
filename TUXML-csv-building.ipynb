{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (1150,6015,6026,6717,7350,7676,7726,10442) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (1150,6015,6026,6717,7350,7676,7726,8507,10442) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (1150,2722,6015,6026,6717,7350,7676,7726,9949) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (1150,6015,6026,6717,7350,7676,7726) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "TUXML_CSV_FILENAMES = ['config_bdd30000-40000.csv', 'config_bdd40000-60000.csv', 'config_bdd60000-90000.csv', 'config_bdd90000-100000.csv']\n",
    "# ['config_bdd30000-40000.csv', 'config_bdd90000-100000.csv']\n",
    "\n",
    "#pd_chunks = []\n",
    "#for csv_filename in TUXML_CSV_FILENAMES:\n",
    "    # sanity check CSV\n",
    "    #with open(csv_filename, \"r\") as file:\n",
    "    #    k = file.readline()\n",
    "    #    t = k.split(\",\")\n",
    "    #    s = set(t)\n",
    "    #    assert(len(t) == len(s)) # unique number of options/features/column names\n",
    "\n",
    "    # parsing for real with pandas \n",
    "    #c_pd = pd.read_csv(open(csv_filename, \"r\"))\n",
    "    #pd_chunks.append(c_pd)\n",
    "    #print(\"DONE for\", csv_filename)  \n",
    "pd_csvs = [pd.read_csv(f) for f in TUXML_CSV_FILENAMES]\n",
    "combined_pd = pd.concat(pd_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pd.to_pickle('config_bdd30-100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69459"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert (len(combined_pd) == 20001)\n",
    "len(combined_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9939, 19683, 29837, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd_csvs[0]), len(pd_csvs[1]), len(pd_csvs[2]), len(pd_csvs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_head = [\"cid\", \"time\", \"date\"] # \"compile\"\n",
    "size_methods = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \n",
    "              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size (#configs/#options) of the dataset (69459, 12798)\n",
      "Number of options with only one value (eg always y): (2885, 1)\n",
      "Non tri-state value options (eg string or integer or hybrid values): (174, 1) \n",
      "Predictor variables: 12624\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69459 entries, 0 to 9999\n",
      "Columns: 12798 entries, cid to NETWORK_FILESYSTEMS\n",
      "dtypes: float64(30), int64(234), object(12534)\n",
      "memory usage: 53.6 GB\n"
     ]
    }
   ],
   "source": [
    "### basic stats about options and unique values \n",
    "## could be extended/improved \n",
    "\n",
    "tri_state_values = ['y', 'n', 'm']\n",
    "\n",
    "ftuniques = []\n",
    "freq_ymn_features = []\n",
    "non_tristate_options = []\n",
    "\n",
    "for col in combined_pd:\n",
    "    ft = combined_pd[col]    \n",
    "    # eg always \"y\"\n",
    "    if len(ft.unique()) == 1:\n",
    "        ftuniques.append(col)\n",
    "    # only tri-state values (y, n, m) (possible TODO: handle numerical/string options)    \n",
    "    elif all(x in tri_state_values for x in ft.unique()):     #len(ft.unique()) == 3: \n",
    "        freq = ft.value_counts(normalize=True)\n",
    "        freqy = 0\n",
    "        freqn = 0\n",
    "        freqm = 0\n",
    "        if ('y' in freq.index):\n",
    "            freqy = freq['y']\n",
    "        if ('n' in freq.index):\n",
    "            freqn = freq['n']\n",
    "        if ('m' in freq.index):\n",
    "            freqm = freq['m']\n",
    "        freq_ymn_features.append((col, freqy, freqm, freqn))\n",
    "    else:\n",
    "        if not (col in size_methods): \n",
    "            non_tristate_options.append(col)\n",
    "        \n",
    "\n",
    "### TODO: we want to keep all quantitative values!\n",
    "# non_tristate_options.remove('LZO') # ('vmlinux')\n",
    "\n",
    "# we want to keep measurements (that are not tristate ;)) \n",
    "# non_tristate_options = list(set(non_tristate_options) - set(size_methods))\n",
    "\n",
    "#### print options with unique values\n",
    "# options with only one value eg always \"y\"\n",
    "#i = 0\n",
    "#for ft in ftuniques:\n",
    "#    print(ft + \" (\" + str(i) + \")\")\n",
    "#    i = i + 1\n",
    "\n",
    "print(\"Original size (#configs/#options) of the dataset \" + str(combined_pd.shape))\n",
    "print (\"Number of options with only one value (eg always y): \" + str(pd.DataFrame(ftuniques).shape))\n",
    "\n",
    "# maybe we can drop options with only one unique value (no interest for machine learning)\n",
    "# TODO: maybe we can rely on more traditional feature reduction techniques\n",
    "# TODO: need to think about *when* to apply the removal \n",
    "\n",
    "#rawtuxdata.drop(columns=ftuniques,inplace=True) \n",
    "\n",
    "## non_tristate_options include basic stuff like date, time, cid but also string/numerical options\n",
    "print (\"Non tri-state value options (eg string or integer or hybrid values): \" \n",
    "       + str(pd.DataFrame(non_tristate_options).shape) + \" \") \n",
    "#      + str(pd.DataFrame(non_tristate_options)))\n",
    "\n",
    "\n",
    "print (\"Predictor variables: \" + str(combined_pd.drop(columns=non_tristate_options).columns.size))\n",
    "# frequency of y, m, and n values \n",
    "#plt.figure()\n",
    "#pd.DataFrame(freq_ymn_features, columns=[\"feature\", \"freqy\", \"freqm\", \"freqn\"]).plot(kind='hist', alpha=0.8) #plot()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "combined_pd.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking: top (20)\n",
      "1. feature AIC79XX_BUILD_FIRMWARE 2536 (0.444362)\n",
      "2. feature AIC7XXX_BUILD_FIRMWARE 1789 (0.305322)\n",
      "3. feature WANXL_BUILD_FIRMWARE 10508 (0.126132)\n",
      "4. feature DRM_VBOXVIDEO 7999 (0.075337)\n",
      "5. feature IPV6 1782 (0.008694)\n",
      "6. feature FORTIFY_SOURCE 5334 (0.005939)\n",
      "7. feature GENERIC_ALLOCATOR 11909 (0.005908)\n",
      "8. feature UBSAN_ALIGNMENT 2727 (0.003383)\n",
      "9. feature INFINIBAND_ADDR_TRANS 6303 (0.003307)\n",
      "10. feature UBSAN_NULL 2734 (0.001326)\n",
      "11. feature UEVENT_HELPER_PATH 1356 (0.001171)\n",
      "12. feature TTY_PRINTK 689 (0.000877)\n",
      "13. feature CRC32_SLICEBY8 8756 (0.000728)\n",
      "14. feature PARIDE_EPIA 3011 (0.000655)\n",
      "15. feature BATTERY_OLPC 11041 (0.000655)\n",
      "16. feature FPGA_MGR_SOCFPGA 2017 (0.000634)\n",
      "17. feature PKCS7_MESSAGE_PARSER 10230 (0.000631)\n",
      "18. feature DRM_TTM 3278 (0.000609)\n",
      "19. feature MCP4725 10516 (0.000607)\n",
      "20. feature DRM_DEBUG_MM_SELFTEST 2697 (0.000595)\n",
      "Accuracy score: 1.00\n",
      "Precision score: 1.00\n",
      "Recall score: 1.00\n",
      "F1 score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "LEARN_COMPILATION_SUCCESS = True # costly in time and space \n",
    "compilation_status_column_name = 'compile_success'\n",
    "\n",
    "def encode_data_compilation(rawtuxdata):\n",
    "    lae = LabelEncoder()\n",
    "    # we save quantitative values we want (here vmlinux, TODO: generalize)\n",
    "    # the key idea is that the labelling encoder should not be applied to this kind of values (only to predictor variables!)\n",
    "    # vml = rawtuxdata['LZO'] # rawtuxdata['vmlinux'] \n",
    "    o_sizes = rawtuxdata[size_methods]\n",
    "\n",
    "    # we may remove non tri state options, but TODO there are perhaps some interesting options (numerical or string) here\n",
    "    #tuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=['vmlinux']).apply(le.fit_transform)\n",
    "    tuxdata_for_compilation = rawtuxdata.drop(columns=non_tristate_options).drop(columns=size_methods).apply(lae.fit_transform)\n",
    "\n",
    "    #tuxdata['vmlinux'] = vml \n",
    "    tuxdata_for_compilation[size_methods] = o_sizes\n",
    "    # we can ue vmlinux since it has been restored thanks to previous line\n",
    "    tuxdata_for_compilation[compilation_status_column_name] = tuxdata_for_compilation['vmlinux'] != -1\n",
    "    return tuxdata_for_compilation\n",
    "\n",
    "def learn_compilation_success(tuxdata_for_compilation):\n",
    "    TESTING_SIZE=0.1 \n",
    "    X_train, X_test, y_train, y_test = train_test_split(tuxdata_for_compilation.drop(columns=size_methods).drop(columns=compilation_status_column_name), tuxdata_for_compilation[compilation_status_column_name], test_size=TESTING_SIZE, random_state=0)  \n",
    "    clf = tree.DecisionTreeClassifier() #GradientBoostingClassifier(n_estimators=100) #RandomForestRegressor(n_estimators=100) #   #GradientBoostingRegressor(n_estimators=100)  \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]    \n",
    "\n",
    "    TOP_FT_IMPORTANCE=20\n",
    "    print(\"Feature ranking: \" + \"top (\" + str(TOP_FT_IMPORTANCE) + \")\")\n",
    "    for f in range(TOP_FT_IMPORTANCE): # len(indices)\n",
    "        print(\"%d. feature %s %d (%f)\" % (f + 1, tuxdata_for_compilation.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "   \n",
    "    \n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=tuxdata_for_compilation.drop(columns=size_methods).drop(columns=compilation_status_column_name).columns,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(\"TUXML_compilation_failures\")\n",
    "    \n",
    "    acc = accuracy_score (y_test, y_pred)\n",
    "    prec = precision_score (y_test, y_pred)\n",
    "    reca = recall_score (y_test, y_pred)\n",
    "    f1 = f1_score (y_test, y_pred)\n",
    "    print(\"Accuracy score: %.2f\" % (acc))\n",
    "    print(\"Precision score: %.2f\" % (prec))\n",
    "    print(\"Recall score: %.2f\" % (reca))\n",
    "    print(\"F1 score: %.2f\" % (f1))\n",
    "\n",
    "if (LEARN_COMPILATION_SUCCESS):\n",
    "    tuxdata_for_compilation = encode_data_compilation(combined_pd)\n",
    "    tuxdata_for_compilation [compilation_status_column_name].describe() # TODO?\n",
    "    learn_compilation_success(tuxdata_for_compilation)\n",
    "    del tuxdata_for_compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation failures: 3534 out of 69459 ( 5.087893577506155 %)\n"
     ]
    }
   ],
   "source": [
    "compilation_failures = len(combined_pd.query(\"vmlinux == -1\").index)\n",
    "compilation_successes = len(combined_pd.query(\"vmlinux != -1\").index)\n",
    "n_compilations = len(combined_pd.index)\n",
    "assert(compilation_successes + compilation_failures == n_compilations)\n",
    "compilation_failure_percentage = (compilation_failures / n_compilations) * 100\n",
    "print(\"compilation failures:\", compilation_failures, \"out of\", n_compilations, \"(\", compilation_failure_percentage, \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
